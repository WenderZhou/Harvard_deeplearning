{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import tensorflow.keras as keras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 50000\n",
      "number of test examples = 10000\n",
      "X_train shape: (50000, 32, 32, 3)\n",
      "Y_train shape: (50000, 10)\n",
      "X_test shape: (10000, 32, 32, 3)\n",
      "Y_test shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "(X_train_orig, Y_train_orig), (X_test_orig, Y_test_orig) = cifar10.load_data()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "X_train_mean = np.mean(X_train, axis=0)\n",
    "X_train -= X_train_mean\n",
    "X_test -= X_train_mean\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "Y_train = keras.utils.to_categorical(Y_train_orig, 10)\n",
    "Y_test = keras.utils.to_categorical(Y_test_orig, 10)    \n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a learning rate scheduler to change the learning rate\n",
    "def my_schedule(epoch):\n",
    "    if epoch > 180:\n",
    "        learning_rate = 5e-7\n",
    "    elif epoch > 160:\n",
    "        learning_rate = 1e-6\n",
    "    elif epoch > 120:\n",
    "        learning_rate = 1e-5\n",
    "    elif epoch > 80:\n",
    "        learning_rate = 1e-4\n",
    "    else:\n",
    "        learning_rate = 1e-3\n",
    "    print('Learning rate: ', learning_rate)\n",
    "    return learning_rate\n",
    "\n",
    "scheduler = LearningRateScheduler(my_schedule)\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'Res_cifar10_model.h5' \n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Model: \"ResNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_conv2d_1 (Conv2D)       (None, 32, 32, 16)   448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_bn_1 (BatchNormalizatio (None, 32, 32, 16)   64          conv2_1_conv2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 16)   0           conv2_1_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_conv2d_2 (Conv2D)       (None, 32, 32, 16)   2320        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_conv2d_shortcut (Conv2D (None, 32, 32, 16)   64          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_bn_2 (BatchNormalizatio (None, 32, 32, 16)   64          conv2_1_conv2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_bn_shortcut (BatchNorma (None, 32, 32, 16)   64          conv2_1_conv2d_shortcut[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 32, 16)   0           conv2_1_bn_2[0][0]               \n",
      "                                                                 conv2_1_bn_shortcut[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_conv2d_1 (Conv2D)       (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_bn_1 (BatchNormalizatio (None, 32, 32, 16)   64          conv2_2_conv2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           conv2_2_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_conv2d_2 (Conv2D)       (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_bn_2 (BatchNormalizatio (None, 32, 32, 16)   64          conv2_2_conv2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 16)   0           conv2_2_bn_2[0][0]               \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_conv2d_1 (Conv2D)       (None, 32, 32, 16)   2320        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_bn_1 (BatchNormalizatio (None, 32, 32, 16)   64          conv2_3_conv2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 16)   0           conv2_3_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_conv2d_2 (Conv2D)       (None, 32, 32, 16)   2320        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_bn_2 (BatchNormalizatio (None, 32, 32, 16)   64          conv2_3_conv2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 16)   0           conv2_3_bn_2[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_conv2d_1 (Conv2D)       (None, 16, 16, 32)   4640        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_bn_1 (BatchNormalizatio (None, 16, 16, 32)   128         conv3_1_conv2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 32)   0           conv3_1_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_conv2d_2 (Conv2D)       (None, 16, 16, 32)   9248        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_conv2d_shortcut (Conv2D (None, 16, 16, 32)   544         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_bn_2 (BatchNormalizatio (None, 16, 16, 32)   128         conv3_1_conv2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_bn_shortcut (BatchNorma (None, 16, 16, 32)   128         conv3_1_conv2d_shortcut[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 16, 32)   0           conv3_1_bn_2[0][0]               \n",
      "                                                                 conv3_1_bn_shortcut[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 32)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_conv2d_1 (Conv2D)       (None, 16, 16, 32)   9248        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_bn_1 (BatchNormalizatio (None, 16, 16, 32)   128         conv3_2_conv2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 32)   0           conv3_2_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_conv2d_2 (Conv2D)       (None, 16, 16, 32)   9248        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_bn_2 (BatchNormalizatio (None, 16, 16, 32)   128         conv3_2_conv2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 32)   0           conv3_2_bn_2[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_conv2d_1 (Conv2D)       (None, 16, 16, 32)   9248        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_bn_1 (BatchNormalizatio (None, 16, 16, 32)   128         conv3_3_conv2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 32)   0           conv3_3_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_conv2d_2 (Conv2D)       (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_bn_2 (BatchNormalizatio (None, 16, 16, 32)   128         conv3_3_conv2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 32)   0           conv3_3_bn_2[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_conv2d_1 (Conv2D)       (None, 8, 8, 64)     18496       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_bn_1 (BatchNormalizatio (None, 8, 8, 64)     256         conv4_1_conv2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 8, 8, 64)     0           conv4_1_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_conv2d_2 (Conv2D)       (None, 8, 8, 64)     36928       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_conv2d_shortcut (Conv2D (None, 8, 8, 64)     2112        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_bn_2 (BatchNormalizatio (None, 8, 8, 64)     256         conv4_1_conv2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_bn_shortcut (BatchNorma (None, 8, 8, 64)     256         conv4_1_conv2d_shortcut[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 64)     0           conv4_1_bn_2[0][0]               \n",
      "                                                                 conv4_1_bn_shortcut[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 64)     0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_conv2d_1 (Conv2D)       (None, 8, 8, 64)     36928       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_bn_1 (BatchNormalizatio (None, 8, 8, 64)     256         conv4_2_conv2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 64)     0           conv4_2_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_conv2d_2 (Conv2D)       (None, 8, 8, 64)     36928       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_bn_2 (BatchNormalizatio (None, 8, 8, 64)     256         conv4_2_conv2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 64)     0           conv4_2_bn_2[0][0]               \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_conv2d_1 (Conv2D)       (None, 8, 8, 64)     36928       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_bn_1 (BatchNormalizatio (None, 8, 8, 64)     256         conv4_3_conv2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 64)     0           conv4_3_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_conv2d_2 (Conv2D)       (None, 8, 8, 64)     36928       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_bn_2 (BatchNormalizatio (None, 8, 8, 64)     256         conv4_3_conv2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 64)     0           conv4_3_bn_2[0][0]               \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 64)     0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 64)           0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc10 (Dense)                    (None, 10)           650         flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 272,570\n",
      "Trainable params: 271,002\n",
      "Non-trainable params: 1,568\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from cifar10_net import ResNet20\n",
    "model1 = ResNet20(input_shape = (32, 32, 3), classes = 10)\n",
    "model1.compile(optimizer=optimizers.Adam(learning_rate=my_schedule(0)), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    data_format=None,\n",
    "    validation_split = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 1/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.4441 - accuracy: 0.4748\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56150, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 134s 86ms/step - loss: 1.4439 - accuracy: 0.4748 - val_loss: 1.2795 - val_accuracy: 0.5615\n",
      "Learning rate:  0.001\n",
      "Epoch 2/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.9939 - accuracy: 0.6471\n",
      "Epoch 00002: val_accuracy improved from 0.56150 to 0.59690, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 139s 89ms/step - loss: 0.9939 - accuracy: 0.6471 - val_loss: 1.2056 - val_accuracy: 0.5969\n",
      "Learning rate:  0.001\n",
      "Epoch 3/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.8248 - accuracy: 0.7105\n",
      "Epoch 00003: val_accuracy improved from 0.59690 to 0.67940, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 132s 85ms/step - loss: 0.8248 - accuracy: 0.7106 - val_loss: 1.0074 - val_accuracy: 0.6794\n",
      "Learning rate:  0.001\n",
      "Epoch 4/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.7309 - accuracy: 0.7455\n",
      "Epoch 00004: val_accuracy improved from 0.67940 to 0.71490, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 132s 85ms/step - loss: 0.7307 - accuracy: 0.7456 - val_loss: 0.8508 - val_accuracy: 0.7149\n",
      "Learning rate:  0.001\n",
      "Epoch 5/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6627 - accuracy: 0.7702\n",
      "Epoch 00005: val_accuracy improved from 0.71490 to 0.72170, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 132s 85ms/step - loss: 0.6626 - accuracy: 0.7702 - val_loss: 0.8427 - val_accuracy: 0.7217\n",
      "Learning rate:  0.001\n",
      "Epoch 6/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6115 - accuracy: 0.7902\n",
      "Epoch 00006: val_accuracy did not improve from 0.72170\n",
      "1563/1563 [==============================] - 132s 85ms/step - loss: 0.6116 - accuracy: 0.7902 - val_loss: 1.0938 - val_accuracy: 0.6615\n",
      "Learning rate:  0.001\n",
      "Epoch 7/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5664 - accuracy: 0.8045\n",
      "Epoch 00007: val_accuracy improved from 0.72170 to 0.77140, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.5665 - accuracy: 0.8044 - val_loss: 0.6693 - val_accuracy: 0.7714\n",
      "Learning rate:  0.001\n",
      "Epoch 8/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5383 - accuracy: 0.8154\n",
      "Epoch 00008: val_accuracy improved from 0.77140 to 0.81280, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.5382 - accuracy: 0.8155 - val_loss: 0.5559 - val_accuracy: 0.8128\n",
      "Learning rate:  0.001\n",
      "Epoch 9/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5061 - accuracy: 0.8249\n",
      "Epoch 00009: val_accuracy did not improve from 0.81280\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.5062 - accuracy: 0.8249 - val_loss: 0.6084 - val_accuracy: 0.7936\n",
      "Learning rate:  0.001\n",
      "Epoch 10/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4838 - accuracy: 0.8332\n",
      "Epoch 00010: val_accuracy did not improve from 0.81280\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.4840 - accuracy: 0.8331 - val_loss: 0.5832 - val_accuracy: 0.8024\n",
      "Learning rate:  0.001\n",
      "Epoch 11/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4614 - accuracy: 0.8418\n",
      "Epoch 00011: val_accuracy did not improve from 0.81280\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.4612 - accuracy: 0.8419 - val_loss: 0.8333 - val_accuracy: 0.7497\n",
      "Learning rate:  0.001\n",
      "Epoch 12/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4439 - accuracy: 0.8459\n",
      "Epoch 00012: val_accuracy did not improve from 0.81280\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.4438 - accuracy: 0.8460 - val_loss: 0.6686 - val_accuracy: 0.7838\n",
      "Learning rate:  0.001\n",
      "Epoch 13/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4227 - accuracy: 0.8544\n",
      "Epoch 00013: val_accuracy improved from 0.81280 to 0.82660, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.4228 - accuracy: 0.8544 - val_loss: 0.5172 - val_accuracy: 0.8266\n",
      "Learning rate:  0.001\n",
      "Epoch 14/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4060 - accuracy: 0.8591\n",
      "Epoch 00014: val_accuracy did not improve from 0.82660\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.4059 - accuracy: 0.8591 - val_loss: 0.6134 - val_accuracy: 0.8046\n",
      "Learning rate:  0.001\n",
      "Epoch 15/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.3974 - accuracy: 0.8620\n",
      "Epoch 00015: val_accuracy improved from 0.82660 to 0.83840, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 134s 86ms/step - loss: 0.3974 - accuracy: 0.8619 - val_loss: 0.4835 - val_accuracy: 0.8384\n",
      "Learning rate:  0.001\n",
      "Epoch 16/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8656\n",
      "Epoch 00016: val_accuracy improved from 0.83840 to 0.84270, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 134s 86ms/step - loss: 0.3846 - accuracy: 0.8655 - val_loss: 0.4816 - val_accuracy: 0.8427\n",
      "Learning rate:  0.001\n",
      "Epoch 17/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.3719 - accuracy: 0.8715\n",
      "Epoch 00017: val_accuracy did not improve from 0.84270\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.3721 - accuracy: 0.8714 - val_loss: 0.6563 - val_accuracy: 0.7948\n",
      "Learning rate:  0.001\n",
      "Epoch 18/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.3578 - accuracy: 0.8763\n",
      "Epoch 00018: val_accuracy did not improve from 0.84270\n",
      "1563/1563 [==============================] - 132s 85ms/step - loss: 0.3576 - accuracy: 0.8763 - val_loss: 0.5148 - val_accuracy: 0.8316\n",
      "Learning rate:  0.001\n",
      "Epoch 19/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.3516 - accuracy: 0.8777\n",
      "Epoch 00019: val_accuracy improved from 0.84270 to 0.84850, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.3515 - accuracy: 0.8777 - val_loss: 0.4570 - val_accuracy: 0.8485\n",
      "Learning rate:  0.001\n",
      "Epoch 20/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.3372 - accuracy: 0.8814\n",
      "Epoch 00020: val_accuracy improved from 0.84850 to 0.85680, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.3373 - accuracy: 0.8814 - val_loss: 0.4385 - val_accuracy: 0.8568\n",
      "Learning rate:  0.001\n",
      "Epoch 21/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.3318 - accuracy: 0.8853\n",
      "Epoch 00021: val_accuracy did not improve from 0.85680\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.3319 - accuracy: 0.8853 - val_loss: 0.4948 - val_accuracy: 0.8355\n",
      "Learning rate:  0.001\n",
      "Epoch 22/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.3196 - accuracy: 0.8879\n",
      "Epoch 00022: val_accuracy did not improve from 0.85680\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.3198 - accuracy: 0.8878 - val_loss: 0.4741 - val_accuracy: 0.8438\n",
      "Learning rate:  0.001\n",
      "Epoch 23/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.3149 - accuracy: 0.8893\n",
      "Epoch 00023: val_accuracy did not improve from 0.85680\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.3151 - accuracy: 0.8892 - val_loss: 0.4593 - val_accuracy: 0.8503\n",
      "Learning rate:  0.001\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.3047 - accuracy: 0.8937\n",
      "Epoch 00024: val_accuracy did not improve from 0.85680\n",
      "1563/1563 [==============================] - 134s 85ms/step - loss: 0.3046 - accuracy: 0.8937 - val_loss: 0.5930 - val_accuracy: 0.8238\n",
      "Learning rate:  0.001\n",
      "Epoch 25/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2998 - accuracy: 0.8937\n",
      "Epoch 00025: val_accuracy did not improve from 0.85680\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.2998 - accuracy: 0.8937 - val_loss: 0.4685 - val_accuracy: 0.8484\n",
      "Learning rate:  0.001\n",
      "Epoch 26/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2922 - accuracy: 0.8974\n",
      "Epoch 00026: val_accuracy did not improve from 0.85680\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.2922 - accuracy: 0.8974 - val_loss: 0.5105 - val_accuracy: 0.8395\n",
      "Learning rate:  0.001\n",
      "Epoch 27/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2846 - accuracy: 0.9017\n",
      "Epoch 00027: val_accuracy did not improve from 0.85680\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.2845 - accuracy: 0.9018 - val_loss: 0.4727 - val_accuracy: 0.8495\n",
      "Learning rate:  0.001\n",
      "Epoch 28/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2843 - accuracy: 0.9023\n",
      "Epoch 00028: val_accuracy did not improve from 0.85680\n",
      "1563/1563 [==============================] - 134s 86ms/step - loss: 0.2843 - accuracy: 0.9023 - val_loss: 0.4631 - val_accuracy: 0.8562\n",
      "Learning rate:  0.001\n",
      "Epoch 29/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2719 - accuracy: 0.9044\n",
      "Epoch 00029: val_accuracy did not improve from 0.85680\n",
      "1563/1563 [==============================] - 132s 85ms/step - loss: 0.2718 - accuracy: 0.9044 - val_loss: 0.4810 - val_accuracy: 0.8486\n",
      "Learning rate:  0.001\n",
      "Epoch 30/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2687 - accuracy: 0.9062\n",
      "Epoch 00030: val_accuracy did not improve from 0.85680\n",
      "1563/1563 [==============================] - 132s 85ms/step - loss: 0.2686 - accuracy: 0.9062 - val_loss: 0.4888 - val_accuracy: 0.8503\n",
      "Learning rate:  0.001\n",
      "Epoch 31/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2660 - accuracy: 0.9077\n",
      "Epoch 00031: val_accuracy improved from 0.85680 to 0.85760, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.2660 - accuracy: 0.9077 - val_loss: 0.4672 - val_accuracy: 0.8576\n",
      "Learning rate:  0.001\n",
      "Epoch 32/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2566 - accuracy: 0.9105\n",
      "Epoch 00032: val_accuracy did not improve from 0.85760\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.2565 - accuracy: 0.9106 - val_loss: 0.4512 - val_accuracy: 0.8572\n",
      "Learning rate:  0.001\n",
      "Epoch 33/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2528 - accuracy: 0.9108\n",
      "Epoch 00033: val_accuracy did not improve from 0.85760\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.2528 - accuracy: 0.9108 - val_loss: 0.4647 - val_accuracy: 0.8533\n",
      "Learning rate:  0.001\n",
      "Epoch 34/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2477 - accuracy: 0.9145\n",
      "Epoch 00034: val_accuracy improved from 0.85760 to 0.87120, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.2475 - accuracy: 0.9146 - val_loss: 0.4004 - val_accuracy: 0.8712\n",
      "Learning rate:  0.001\n",
      "Epoch 35/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2396 - accuracy: 0.9162\n",
      "Epoch 00035: val_accuracy improved from 0.87120 to 0.87340, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.2397 - accuracy: 0.9162 - val_loss: 0.4207 - val_accuracy: 0.8734\n",
      "Learning rate:  0.001\n",
      "Epoch 36/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2372 - accuracy: 0.9170\n",
      "Epoch 00036: val_accuracy did not improve from 0.87340\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.2372 - accuracy: 0.9170 - val_loss: 0.5102 - val_accuracy: 0.8458\n",
      "Learning rate:  0.001\n",
      "Epoch 37/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2311 - accuracy: 0.9196\n",
      "Epoch 00037: val_accuracy did not improve from 0.87340\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.2312 - accuracy: 0.9196 - val_loss: 0.4529 - val_accuracy: 0.8640\n",
      "Learning rate:  0.001\n",
      "Epoch 38/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2309 - accuracy: 0.9191\n",
      "Epoch 00038: val_accuracy did not improve from 0.87340\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.2309 - accuracy: 0.9192 - val_loss: 0.4088 - val_accuracy: 0.8718\n",
      "Learning rate:  0.001\n",
      "Epoch 39/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2217 - accuracy: 0.9218\n",
      "Epoch 00039: val_accuracy did not improve from 0.87340\n",
      "1563/1563 [==============================] - 132s 85ms/step - loss: 0.2217 - accuracy: 0.9218 - val_loss: 0.4180 - val_accuracy: 0.8701\n",
      "Learning rate:  0.001\n",
      "Epoch 40/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2172 - accuracy: 0.9233\n",
      "Epoch 00040: val_accuracy did not improve from 0.87340\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.2172 - accuracy: 0.9232 - val_loss: 0.4867 - val_accuracy: 0.8540\n",
      "Learning rate:  0.001\n",
      "Epoch 41/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2183 - accuracy: 0.9231\n",
      "Epoch 00041: val_accuracy did not improve from 0.87340\n",
      "1563/1563 [==============================] - 132s 85ms/step - loss: 0.2184 - accuracy: 0.9231 - val_loss: 0.4938 - val_accuracy: 0.8558\n",
      "Learning rate:  0.001\n",
      "Epoch 42/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2129 - accuracy: 0.9257\n",
      "Epoch 00042: val_accuracy did not improve from 0.87340\n",
      "1563/1563 [==============================] - 134s 86ms/step - loss: 0.2128 - accuracy: 0.9256 - val_loss: 0.4685 - val_accuracy: 0.8639\n",
      "Learning rate:  0.001\n",
      "Epoch 43/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2090 - accuracy: 0.9269\n",
      "Epoch 00043: val_accuracy did not improve from 0.87340\n",
      "1563/1563 [==============================] - 135s 86ms/step - loss: 0.2089 - accuracy: 0.9270 - val_loss: 0.5134 - val_accuracy: 0.8535\n",
      "Learning rate:  0.001\n",
      "Epoch 44/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2062 - accuracy: 0.9277\n",
      "Epoch 00044: val_accuracy did not improve from 0.87340\n",
      "1563/1563 [==============================] - 134s 86ms/step - loss: 0.2062 - accuracy: 0.9277 - val_loss: 0.4048 - val_accuracy: 0.8718\n",
      "Learning rate:  0.001\n",
      "Epoch 45/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2051 - accuracy: 0.9275\n",
      "Epoch 00045: val_accuracy did not improve from 0.87340\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.2051 - accuracy: 0.9275 - val_loss: 0.4354 - val_accuracy: 0.8659\n",
      "Learning rate:  0.001\n",
      "Epoch 46/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2001 - accuracy: 0.9294\n",
      "Epoch 00046: val_accuracy did not improve from 0.87340\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.2002 - accuracy: 0.9294 - val_loss: 0.4353 - val_accuracy: 0.8673\n",
      "Learning rate:  0.001\n",
      "Epoch 47/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1984 - accuracy: 0.9310\n",
      "Epoch 00047: val_accuracy improved from 0.87340 to 0.87620, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 134s 86ms/step - loss: 0.1984 - accuracy: 0.9310 - val_loss: 0.4027 - val_accuracy: 0.8762\n",
      "Learning rate:  0.001\n",
      "Epoch 48/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1937 - accuracy: 0.9310\n",
      "Epoch 00048: val_accuracy improved from 0.87620 to 0.88630, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 134s 86ms/step - loss: 0.1937 - accuracy: 0.9310 - val_loss: 0.3726 - val_accuracy: 0.8863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 49/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1892 - accuracy: 0.9333\n",
      "Epoch 00049: val_accuracy improved from 0.88630 to 0.88740, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.1891 - accuracy: 0.9333 - val_loss: 0.3629 - val_accuracy: 0.8874\n",
      "Learning rate:  0.001\n",
      "Epoch 50/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1843 - accuracy: 0.9341\n",
      "Epoch 00050: val_accuracy did not improve from 0.88740\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.1844 - accuracy: 0.9341 - val_loss: 0.4040 - val_accuracy: 0.8781\n",
      "Learning rate:  0.001\n",
      "Epoch 51/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1846 - accuracy: 0.9344\n",
      "Epoch 00051: val_accuracy did not improve from 0.88740\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.1846 - accuracy: 0.9344 - val_loss: 0.3850 - val_accuracy: 0.8813\n",
      "Learning rate:  0.001\n",
      "Epoch 52/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1838 - accuracy: 0.9353\n",
      "Epoch 00052: val_accuracy did not improve from 0.88740\n",
      "1563/1563 [==============================] - 132s 85ms/step - loss: 0.1838 - accuracy: 0.9353 - val_loss: 0.4752 - val_accuracy: 0.8573\n",
      "Learning rate:  0.001\n",
      "Epoch 53/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1830 - accuracy: 0.9348\n",
      "Epoch 00053: val_accuracy did not improve from 0.88740\n",
      "1563/1563 [==============================] - 132s 85ms/step - loss: 0.1829 - accuracy: 0.9348 - val_loss: 0.4335 - val_accuracy: 0.8693\n",
      "Learning rate:  0.001\n",
      "Epoch 54/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1771 - accuracy: 0.9371\n",
      "Epoch 00054: val_accuracy did not improve from 0.88740\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.1770 - accuracy: 0.9371 - val_loss: 0.3641 - val_accuracy: 0.8865\n",
      "Learning rate:  0.001\n",
      "Epoch 55/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1733 - accuracy: 0.9376\n",
      "Epoch 00055: val_accuracy did not improve from 0.88740\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.1733 - accuracy: 0.9376 - val_loss: 0.3954 - val_accuracy: 0.8841\n",
      "Learning rate:  0.001\n",
      "Epoch 56/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1706 - accuracy: 0.9398\n",
      "Epoch 00056: val_accuracy did not improve from 0.88740\n",
      "1563/1563 [==============================] - 134s 86ms/step - loss: 0.1706 - accuracy: 0.9398 - val_loss: 0.3947 - val_accuracy: 0.8844\n",
      "Learning rate:  0.001\n",
      "Epoch 57/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1690 - accuracy: 0.9392\n",
      "Epoch 00057: val_accuracy did not improve from 0.88740\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.1690 - accuracy: 0.9392 - val_loss: 0.4562 - val_accuracy: 0.8720\n",
      "Learning rate:  0.001\n",
      "Epoch 58/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1651 - accuracy: 0.9407\n",
      "Epoch 00058: val_accuracy did not improve from 0.88740\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.1651 - accuracy: 0.9407 - val_loss: 0.4184 - val_accuracy: 0.8765\n",
      "Learning rate:  0.001\n",
      "Epoch 59/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1670 - accuracy: 0.9394\n",
      "Epoch 00059: val_accuracy did not improve from 0.88740\n",
      "1563/1563 [==============================] - 132s 85ms/step - loss: 0.1671 - accuracy: 0.9393 - val_loss: 0.4368 - val_accuracy: 0.8741\n",
      "Learning rate:  0.001\n",
      "Epoch 60/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1658 - accuracy: 0.9413\n",
      "Epoch 00060: val_accuracy did not improve from 0.88740\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.1658 - accuracy: 0.9413 - val_loss: 0.5031 - val_accuracy: 0.8591\n",
      "Learning rate:  0.001\n",
      "Epoch 61/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1634 - accuracy: 0.9412\n",
      "Epoch 00061: val_accuracy did not improve from 0.88740\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.1633 - accuracy: 0.9412 - val_loss: 0.4644 - val_accuracy: 0.8660\n",
      "Learning rate:  0.001\n",
      "Epoch 62/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1606 - accuracy: 0.9426\n",
      "Epoch 00062: val_accuracy did not improve from 0.88740\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.1606 - accuracy: 0.9426 - val_loss: 0.4681 - val_accuracy: 0.8691\n",
      "Learning rate:  0.001\n",
      "Epoch 63/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1537 - accuracy: 0.9451\n",
      "Epoch 00063: val_accuracy did not improve from 0.88740\n",
      "1563/1563 [==============================] - 132s 85ms/step - loss: 0.1537 - accuracy: 0.9451 - val_loss: 0.5170 - val_accuracy: 0.8604\n",
      "Learning rate:  0.001\n",
      "Epoch 64/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1595 - accuracy: 0.9441\n",
      "Epoch 00064: val_accuracy did not improve from 0.88740\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.1594 - accuracy: 0.9441 - val_loss: 0.4204 - val_accuracy: 0.8793\n",
      "Learning rate:  0.001\n",
      "Epoch 65/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1521 - accuracy: 0.9457\n",
      "Epoch 00065: val_accuracy improved from 0.88740 to 0.88830, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.1522 - accuracy: 0.9457 - val_loss: 0.3927 - val_accuracy: 0.8883\n",
      "Learning rate:  0.001\n",
      "Epoch 66/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1511 - accuracy: 0.9457\n",
      "Epoch 00066: val_accuracy did not improve from 0.88830\n",
      "1563/1563 [==============================] - 134s 85ms/step - loss: 0.1511 - accuracy: 0.9456 - val_loss: 0.4150 - val_accuracy: 0.8789\n",
      "Learning rate:  0.001\n",
      "Epoch 67/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1498 - accuracy: 0.9465\n",
      "Epoch 00067: val_accuracy did not improve from 0.88830\n",
      "1563/1563 [==============================] - 134s 86ms/step - loss: 0.1498 - accuracy: 0.9466 - val_loss: 0.4163 - val_accuracy: 0.8801\n",
      "Learning rate:  0.001\n",
      "Epoch 68/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1507 - accuracy: 0.9472\n",
      "Epoch 00068: val_accuracy did not improve from 0.88830\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.1507 - accuracy: 0.9472 - val_loss: 0.3966 - val_accuracy: 0.8820\n",
      "Learning rate:  0.001\n",
      "Epoch 69/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1451 - accuracy: 0.9481\n",
      "Epoch 00069: val_accuracy did not improve from 0.88830\n",
      "1563/1563 [==============================] - 132s 85ms/step - loss: 0.1451 - accuracy: 0.9482 - val_loss: 0.4303 - val_accuracy: 0.8817\n",
      "Learning rate:  0.001\n",
      "Epoch 70/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1465 - accuracy: 0.9473\n",
      "Epoch 00070: val_accuracy did not improve from 0.88830\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.1465 - accuracy: 0.9473 - val_loss: 0.5033 - val_accuracy: 0.8643\n",
      "Learning rate:  0.001\n",
      "Epoch 71/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1399 - accuracy: 0.9500\n",
      "Epoch 00071: val_accuracy did not improve from 0.88830\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.1400 - accuracy: 0.9500 - val_loss: 0.4599 - val_accuracy: 0.8729\n",
      "Learning rate:  0.001\n",
      "Epoch 72/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1413 - accuracy: 0.9489\n",
      "Epoch 00072: val_accuracy did not improve from 0.88830\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.1413 - accuracy: 0.9489 - val_loss: 0.4615 - val_accuracy: 0.8750\n",
      "Learning rate:  0.001\n",
      "Epoch 73/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1411 - accuracy: 0.9500\n",
      "Epoch 00073: val_accuracy did not improve from 0.88830\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.1410 - accuracy: 0.9500 - val_loss: 0.4266 - val_accuracy: 0.8812\n",
      "Learning rate:  0.001\n",
      "Epoch 74/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1406 - accuracy: 0.9491\n",
      "Epoch 00074: val_accuracy did not improve from 0.88830\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.1406 - accuracy: 0.9491 - val_loss: 0.4039 - val_accuracy: 0.8858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 75/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1355 - accuracy: 0.9512\n",
      "Epoch 00075: val_accuracy improved from 0.88830 to 0.89030, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.1355 - accuracy: 0.9513 - val_loss: 0.3912 - val_accuracy: 0.8903\n",
      "Learning rate:  0.001\n",
      "Epoch 76/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1337 - accuracy: 0.9530\n",
      "Epoch 00076: val_accuracy did not improve from 0.89030\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.1336 - accuracy: 0.9530 - val_loss: 0.4320 - val_accuracy: 0.8804\n",
      "Learning rate:  0.001\n",
      "Epoch 77/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1322 - accuracy: 0.9529\n",
      "Epoch 00077: val_accuracy did not improve from 0.89030\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.1321 - accuracy: 0.9529 - val_loss: 0.4525 - val_accuracy: 0.8751\n",
      "Learning rate:  0.001\n",
      "Epoch 78/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1323 - accuracy: 0.9537\n",
      "Epoch 00078: val_accuracy did not improve from 0.89030\n",
      "1563/1563 [==============================] - 134s 85ms/step - loss: 0.1323 - accuracy: 0.9537 - val_loss: 0.4061 - val_accuracy: 0.8899\n",
      "Learning rate:  0.001\n",
      "Epoch 79/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1322 - accuracy: 0.9529\n",
      "Epoch 00079: val_accuracy improved from 0.89030 to 0.89530, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.1322 - accuracy: 0.9529 - val_loss: 0.3790 - val_accuracy: 0.8953\n",
      "Learning rate:  0.001\n",
      "Epoch 80/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1292 - accuracy: 0.9528\n",
      "Epoch 00080: val_accuracy did not improve from 0.89530\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.1292 - accuracy: 0.9529 - val_loss: 0.4566 - val_accuracy: 0.8782\n",
      "Learning rate:  0.001\n",
      "Epoch 81/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1266 - accuracy: 0.9547\n",
      "Epoch 00081: val_accuracy did not improve from 0.89530\n",
      "1563/1563 [==============================] - 134s 86ms/step - loss: 0.1266 - accuracy: 0.9547 - val_loss: 0.4393 - val_accuracy: 0.8815\n",
      "Learning rate:  0.0001\n",
      "Epoch 82/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.0954 - accuracy: 0.9672\n",
      "Epoch 00082: val_accuracy improved from 0.89530 to 0.90310, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 134s 86ms/step - loss: 0.0953 - accuracy: 0.9672 - val_loss: 0.3510 - val_accuracy: 0.9031\n",
      "Learning rate:  0.0001\n",
      "Epoch 83/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.0838 - accuracy: 0.9710\n",
      "Epoch 00083: val_accuracy did not improve from 0.90310\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.0838 - accuracy: 0.9710 - val_loss: 0.3601 - val_accuracy: 0.9017\n",
      "Learning rate:  0.0001\n",
      "Epoch 84/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.0741 - accuracy: 0.9747\n",
      "Epoch 00084: val_accuracy improved from 0.90310 to 0.90340, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.0740 - accuracy: 0.9747 - val_loss: 0.3536 - val_accuracy: 0.9034\n",
      "Learning rate:  0.0001\n",
      "Epoch 85/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.0739 - accuracy: 0.9752\n",
      "Epoch 00085: val_accuracy improved from 0.90340 to 0.90540, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 134s 86ms/step - loss: 0.0739 - accuracy: 0.9752 - val_loss: 0.3455 - val_accuracy: 0.9054\n",
      "Learning rate:  0.0001\n",
      "Epoch 86/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.0723 - accuracy: 0.9754\n",
      "Epoch 00086: val_accuracy improved from 0.90540 to 0.90550, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.0723 - accuracy: 0.9754 - val_loss: 0.3555 - val_accuracy: 0.9055\n",
      "Learning rate:  0.0001\n",
      "Epoch 87/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.0689 - accuracy: 0.9762\n",
      "Epoch 00087: val_accuracy did not improve from 0.90550\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.0689 - accuracy: 0.9761 - val_loss: 0.3550 - val_accuracy: 0.9049\n",
      "Learning rate:  0.0001\n",
      "Epoch 88/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.0666 - accuracy: 0.9776\n",
      "Epoch 00088: val_accuracy did not improve from 0.90550\n",
      "1563/1563 [==============================] - 134s 86ms/step - loss: 0.0665 - accuracy: 0.9777 - val_loss: 0.3660 - val_accuracy: 0.9044\n",
      "Learning rate:  0.0001\n",
      "Epoch 89/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.0635 - accuracy: 0.9780\n",
      "Epoch 00089: val_accuracy did not improve from 0.90550\n",
      "1563/1563 [==============================] - 134s 86ms/step - loss: 0.0636 - accuracy: 0.9780 - val_loss: 0.3653 - val_accuracy: 0.9054\n",
      "Learning rate:  0.0001\n",
      "Epoch 90/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.0640 - accuracy: 0.9782\n",
      "Epoch 00090: val_accuracy improved from 0.90550 to 0.90570, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 134s 86ms/step - loss: 0.0641 - accuracy: 0.9782 - val_loss: 0.3668 - val_accuracy: 0.9057\n",
      "Learning rate:  0.0001\n",
      "Epoch 91/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.0636 - accuracy: 0.9788\n",
      "Epoch 00091: val_accuracy did not improve from 0.90570\n",
      "1563/1563 [==============================] - 132s 85ms/step - loss: 0.0636 - accuracy: 0.9788 - val_loss: 0.3678 - val_accuracy: 0.9057\n",
      "Learning rate:  0.0001\n",
      "Epoch 92/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.0612 - accuracy: 0.9787\n",
      "Epoch 00092: val_accuracy improved from 0.90570 to 0.90750, saving model to C:\\Users\\Wender\\Notebook\\proj\\saved_models\\ResNet_20_model.h5\n",
      "1563/1563 [==============================] - 132s 85ms/step - loss: 0.0612 - accuracy: 0.9787 - val_loss: 0.3635 - val_accuracy: 0.9075\n",
      "Learning rate:  0.0001\n",
      "Epoch 93/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.0617 - accuracy: 0.9790\n",
      "Epoch 00093: val_accuracy did not improve from 0.90750\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.0617 - accuracy: 0.9790 - val_loss: 0.3716 - val_accuracy: 0.9058\n",
      "Learning rate:  0.0001\n",
      "Epoch 94/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.0597 - accuracy: 0.9795\n",
      "Epoch 00094: val_accuracy did not improve from 0.90750\n",
      "1563/1563 [==============================] - 132s 85ms/step - loss: 0.0597 - accuracy: 0.9795 - val_loss: 0.3675 - val_accuracy: 0.9062\n",
      "Learning rate:  0.0001\n",
      "Epoch 95/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.0600 - accuracy: 0.9792\n",
      "Epoch 00095: val_accuracy did not improve from 0.90750\n",
      "1563/1563 [==============================] - 132s 85ms/step - loss: 0.0600 - accuracy: 0.9792 - val_loss: 0.3826 - val_accuracy: 0.9041\n",
      "Learning rate:  0.0001\n",
      "Epoch 96/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.0584 - accuracy: 0.9797\n",
      "Epoch 00096: val_accuracy did not improve from 0.90750\n",
      "1563/1563 [==============================] - 134s 85ms/step - loss: 0.0584 - accuracy: 0.9797 - val_loss: 0.3736 - val_accuracy: 0.9065\n",
      "Learning rate:  0.0001\n",
      "Epoch 97/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.0576 - accuracy: 0.9799\n",
      "Epoch 00097: val_accuracy did not improve from 0.90750\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.0576 - accuracy: 0.9798 - val_loss: 0.3725 - val_accuracy: 0.9060\n",
      "Learning rate:  0.0001\n",
      "Epoch 98/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.0576 - accuracy: 0.9805\n",
      "Epoch 00098: val_accuracy did not improve from 0.90750\n",
      "1563/1563 [==============================] - 132s 85ms/step - loss: 0.0576 - accuracy: 0.9805 - val_loss: 0.3780 - val_accuracy: 0.9054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.0001\n",
      "Epoch 99/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.0576 - accuracy: 0.9806\n",
      "Epoch 00099: val_accuracy did not improve from 0.90750\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.0575 - accuracy: 0.9806 - val_loss: 0.3857 - val_accuracy: 0.9056\n",
      "Learning rate:  0.0001\n",
      "Epoch 100/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.0561 - accuracy: 0.9803\n",
      "Epoch 00100: val_accuracy did not improve from 0.90750\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.0560 - accuracy: 0.9803 - val_loss: 0.3794 - val_accuracy: 0.9053\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit_generator(datagen.flow(X_train, Y_train, batch_size=32),\n",
    "                              epochs = 100, \n",
    "                              validation_data=(X_test, Y_test),\n",
    "                              callbacks=[scheduler, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc1 = history1.history['accuracy']\n",
    "val_acc1 = history1.history['val_accuracy']\n",
    "\n",
    "fig1,ax1 = plt.subplots(1,1,figsize=(10,6))\n",
    "\n",
    "ax1.plot(acc1, label='Training Accuracy')\n",
    "ax1.plot(val_acc1, label='Validation Accuracy')\n",
    "\n",
    "ax1.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax1.set_ylabel(r'Acc', fontsize=20)\n",
    "ax1.set_title('ResNet20', fontsize=24)\n",
    "\n",
    "ax1.tick_params(labelsize=20)\n",
    "\n",
    "ax1.legend(loc=4, fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
