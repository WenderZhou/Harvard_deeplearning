{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import tensorflow.keras as keras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 50000\n",
      "number of test examples = 10000\n",
      "X_train shape: (50000, 32, 32, 3)\n",
      "Y_train shape: (50000, 10)\n",
      "X_test shape: (10000, 32, 32, 3)\n",
      "Y_test shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "(X_train_orig, Y_train_orig), (X_test_orig, Y_test_orig) = cifar10.load_data()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "X_train_mean = np.mean(X_train, axis=0)\n",
    "X_train -= X_train_mean\n",
    "X_test -= X_train_mean\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "Y_train = keras.utils.to_categorical(Y_train_orig, 10)\n",
    "Y_test = keras.utils.to_categorical(Y_test_orig, 10)    \n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a learning rate scheduler to change the learning rate\n",
    "def my_schedule(epoch):\n",
    "    if epoch > 180:\n",
    "        learning_rate = 5e-7\n",
    "    elif epoch > 160:\n",
    "        learning_rate = 1e-6\n",
    "    elif epoch > 120:\n",
    "        learning_rate = 1e-5\n",
    "    elif epoch > 80:\n",
    "        learning_rate = 1e-4\n",
    "    else:\n",
    "        learning_rate = 1e-3\n",
    "    print('Learning rate: ', learning_rate)\n",
    "    return learning_rate\n",
    "\n",
    "scheduler = LearningRateScheduler(my_schedule)\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'CNN_cifar10_l2_model.h5' \n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\19244\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Learning rate:  0.001\n",
      "Model: \"ResNet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2_1_conv2d_1 (Conv2D)    (None, 32, 32, 16)        448       \n",
      "_________________________________________________________________\n",
      "conv2_1_bn_1 (BatchNormaliza (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2_1_conv2d_2 (Conv2D)    (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2_1_bn_2 (BatchNormaliza (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2_2_conv2d_1 (Conv2D)    (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2_2_bn_1 (BatchNormaliza (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2_2_conv2d_2 (Conv2D)    (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2_2_bn_2 (BatchNormaliza (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2_3_conv2d_1 (Conv2D)    (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2_3_bn_1 (BatchNormaliza (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2_3_conv2d_2 (Conv2D)    (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2_3_bn_2 (BatchNormaliza (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv3_1_conv2d_1 (Conv2D)    (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv3_1_bn_1 (BatchNormaliza (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv3_1_conv2d_2 (Conv2D)    (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv3_1_bn_2 (BatchNormaliza (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv3_2_conv2d_1 (Conv2D)    (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv3_2_bn_1 (BatchNormaliza (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv3_2_conv2d_2 (Conv2D)    (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv3_2_bn_2 (BatchNormaliza (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv3_3_conv2d_1 (Conv2D)    (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv3_3_bn_1 (BatchNormaliza (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv3_3_conv2d_2 (Conv2D)    (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv3_3_bn_2 (BatchNormaliza (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv4_1_conv2d_1 (Conv2D)    (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "conv4_1_bn_1 (BatchNormaliza (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv4_1_conv2d_2 (Conv2D)    (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv4_1_bn_2 (BatchNormaliza (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv4_2_conv2d_1 (Conv2D)    (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv4_2_bn_1 (BatchNormaliza (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv4_2_conv2d_2 (Conv2D)    (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv4_2_bn_2 (BatchNormaliza (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv4_3_conv2d_1 (Conv2D)    (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv4_3_bn_1 (BatchNormaliza (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv4_3_conv2d_2 (Conv2D)    (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv4_3_bn_2 (BatchNormaliza (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "avg_pool (AveragePooling2D)  (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "fc10 (Dense)                 (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 269,402\n",
      "Trainable params: 268,058\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from cifar10_net import CNN20\n",
    "model1 = CNN20(input_shape = (32, 32, 3), classes = 10)\n",
    "model1.compile(optimizer=optimizers.Adam(learning_rate=my_schedule(0)), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    data_format=None,\n",
    "    validation_split = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 1/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.7531 - acc: 0.3709Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 252us/sample - loss: 1.6119 - acc: 0.4554\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.45540, saving model to C:\\Users\\19244\\saved_models\\CNN_20_l2_model.h5\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.7530 - acc: 0.3709 - val_loss: 1.6285 - val_acc: 0.4554\n",
      "Learning rate:  0.001\n",
      "Epoch 2/100\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 1.4068 - acc: 0.5220- ETA: 0s - loss: 1.4077 - acc: 0.Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 258us/sample - loss: 1.2964 - acc: 0.5592\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.45540 to 0.55920, saving model to C:\\Users\\19244\\saved_models\\CNN_20_l2_model.h5\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.4066 - acc: 0.5221 - val_loss: 1.3296 - val_acc: 0.5592\n",
      "Learning rate:  0.001\n",
      "Epoch 3/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 1.1878 - acc: 0.6132Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 271us/sample - loss: 1.5413 - acc: 0.5235\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.55920\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.1878 - acc: 0.6132 - val_loss: 1.6373 - val_acc: 0.5235\n",
      "Learning rate:  0.001\n",
      "Epoch 4/100\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 1.0584 - acc: 0.6680Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 256us/sample - loss: 1.1303 - acc: 0.6496\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.55920 to 0.64960, saving model to C:\\Users\\19244\\saved_models\\CNN_20_l2_model.h5\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 1.0581 - acc: 0.6681 - val_loss: 1.1479 - val_acc: 0.6496\n",
      "Learning rate:  0.001\n",
      "Epoch 5/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.9724 - acc: 0.7017Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 256us/sample - loss: 0.9873 - acc: 0.6998\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.64960 to 0.69980, saving model to C:\\Users\\19244\\saved_models\\CNN_20_l2_model.h5\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.9726 - acc: 0.7017 - val_loss: 1.0029 - val_acc: 0.6998\n",
      "Learning rate:  0.001\n",
      "Epoch 6/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.9129 - acc: 0.7287Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 216us/sample - loss: 0.9493 - acc: 0.7154\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.69980 to 0.71540, saving model to C:\\Users\\19244\\saved_models\\CNN_20_l2_model.h5\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 0.9128 - acc: 0.7287 - val_loss: 0.9676 - val_acc: 0.7154\n",
      "Learning rate:  0.001\n",
      "Epoch 7/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.8660 - acc: 0.7458- ETA: 1s - loss: Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 232us/sample - loss: 0.8827 - acc: 0.7196\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.71540 to 0.71960, saving model to C:\\Users\\19244\\saved_models\\CNN_20_l2_model.h5\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 0.8661 - acc: 0.7458 - val_loss: 0.9678 - val_acc: 0.7196\n",
      "Learning rate:  0.001\n",
      "Epoch 8/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.8332 - acc: 0.7618- ETA: 6s - loss: 0.8323 - acc: 0.762 - ETA: 6s - loss: 0.8321 - acc: 0. - - ETA: 1s - Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 229us/sample - loss: 1.0691 - acc: 0.7172\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.71960\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 0.8330 - acc: 0.7619 - val_loss: 1.0412 - val_acc: 0.7172\n",
      "Learning rate:  0.001\n",
      "Epoch 9/100\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.8033 - acc: 0.7742- ETA: 6s - loss: 0. - ETA: - ETA: 3s - loss: - EEpoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 228us/sample - loss: 0.8290 - acc: 0.7420\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.71960 to 0.74200, saving model to C:\\Users\\19244\\saved_models\\CNN_20_l2_model.h5\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 0.8030 - acc: 0.7743 - val_loss: 0.9449 - val_acc: 0.7420\n",
      "Learning rate:  0.001\n",
      "Epoch 10/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.7839 - acc: 0.7838  ETA: 15s -  - - ETA: 9s  - ETA: 5s - loss:  - ETA: 4s - loss: 0.7838 - acc: 0.78 - ETA: 4s - loss: 0.7840 - acc: 0. - ETA: 4s - - ETA: 2s - los - ETA: 0s - loss: 0.783Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 248us/sample - loss: 0.9039 - acc: 0.7610\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.74200 to 0.76100, saving model to C:\\Users\\19244\\saved_models\\CNN_20_l2_model.h5\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7838 - acc: 0.7839 - val_loss: 0.8778 - val_acc: 0.7610\n",
      "Learning rate:  0.001\n",
      "Epoch 11/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.7596 - acc: 0.7921Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 257us/sample - loss: 0.7965 - acc: 0.7674\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.76100 to 0.76740, saving model to C:\\Users\\19244\\saved_models\\CNN_20_l2_model.h5\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7595 - acc: 0.7922 - val_loss: 0.8654 - val_acc: 0.7674\n",
      "Learning rate:  0.001\n",
      "Epoch 12/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.7509 - acc: 0.7993  ETA: 12s  - ETA: 8s - loss: 0.7506 - ac - ETA: 1s - loss: 0.7510 - ETA: 0s - loss: 0.7513 - acc: 0.7Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 229us/sample - loss: 1.1431 - acc: 0.7233\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.76740\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7513 - acc: 0.7992 - val_loss: 1.0248 - val_acc: 0.7233\n",
      "Learning rate:  0.001\n",
      "Epoch 13/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.7375 - acc: 0.8035- ETA: 8s - - EEpoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 237us/sample - loss: 0.8925 - acc: 0.7047\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.76740\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.7374 - acc: 0.8035 - val_loss: 1.1344 - val_acc: 0.7047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 14/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.7249 - acc: 0.8076Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 232us/sample - loss: 0.8082 - acc: 0.7834\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.76740 to 0.78340, saving model to C:\\Users\\19244\\saved_models\\CNN_20_l2_model.h5\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.7251 - acc: 0.8075 - val_loss: 0.7982 - val_acc: 0.7834\n",
      "Learning rate:  0.001\n",
      "Epoch 15/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.7165 - acc: 0.8124Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 246us/sample - loss: 1.3682 - acc: 0.6950\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.78340\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.7166 - acc: 0.8124 - val_loss: 1.1773 - val_acc: 0.6950\n",
      "Learning rate:  0.001\n",
      "Epoch 16/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.7069 - acc: 0.8169Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 236us/sample - loss: 0.8810 - acc: 0.7940\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.78340 to 0.79400, saving model to C:\\Users\\19244\\saved_models\\CNN_20_l2_model.h5\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.7073 - acc: 0.8167 - val_loss: 0.7802 - val_acc: 0.7940\n",
      "Learning rate:  0.001\n",
      "Epoch 17/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.8245Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 233us/sample - loss: 1.0310 - acc: 0.7454\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.79400\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.6933 - acc: 0.8244 - val_loss: 0.9830 - val_acc: 0.7454\n",
      "Learning rate:  0.001\n",
      "Epoch 18/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6876 - acc: 0.8260Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 239us/sample - loss: 0.8584 - acc: 0.7924\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.79400\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.6875 - acc: 0.8261 - val_loss: 0.8053 - val_acc: 0.7924\n",
      "Learning rate:  0.001\n",
      "Epoch 19/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.6825 - acc: 0.8272Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 245us/sample - loss: 1.0684 - acc: 0.7463\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.79400\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.6827 - acc: 0.8272 - val_loss: 1.0437 - val_acc: 0.7463\n",
      "Learning rate:  0.001\n",
      "Epoch 20/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6766 - acc: 0.8304Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 235us/sample - loss: 0.8176 - acc: 0.7796\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.79400\n",
      "1563/1563 [==============================] - 45s 28ms/step - loss: 0.6765 - acc: 0.8305 - val_loss: 0.8357 - val_acc: 0.7796\n",
      "Learning rate:  0.001\n",
      "Epoch 21/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6705 - acc: 0.8342Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 249us/sample - loss: 0.8580 - acc: 0.7618\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.79400\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.6704 - acc: 0.8342 - val_loss: 0.9102 - val_acc: 0.7618\n",
      "Learning rate:  0.001\n",
      "Epoch 22/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6656 - acc: 0.8338Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 245us/sample - loss: 0.9596 - acc: 0.7702\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.79400\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.6656 - acc: 0.8338 - val_loss: 0.8933 - val_acc: 0.7702\n",
      "Learning rate:  0.001\n",
      "Epoch 23/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6621 - acc: 0.8360Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 226us/sample - loss: 1.0567 - acc: 0.7484\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.79400\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.6621 - acc: 0.8360 - val_loss: 0.9864 - val_acc: 0.7484\n",
      "Learning rate:  0.001\n",
      "Epoch 24/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6545 - acc: 0.8396- ETA: 9s - loss: 0.651 - ETA: 8s - loss: 0 - ETA: 6s - loss:  - ETA: Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 236us/sample - loss: 0.7457 - acc: 0.8203\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.79400 to 0.82030, saving model to C:\\Users\\19244\\saved_models\\CNN_20_l2_model.h5\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6544 - acc: 0.8396 - val_loss: 0.7235 - val_acc: 0.8203\n",
      "Learning rate:  0.001\n",
      "Epoch 25/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.6505 - acc: 0.8411Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 223us/sample - loss: 0.8092 - acc: 0.8128\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.82030\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.6506 - acc: 0.8411 - val_loss: 0.7492 - val_acc: 0.8128\n",
      "Learning rate:  0.001\n",
      "Epoch 26/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.6422 - acc: 0.8446Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 232us/sample - loss: 0.8749 - acc: 0.7695\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.82030\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.6422 - acc: 0.8447 - val_loss: 0.9409 - val_acc: 0.7695\n",
      "Learning rate:  0.001\n",
      "Epoch 27/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6372 - acc: 0.8486Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 235us/sample - loss: 0.9240 - acc: 0.8010\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.82030\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6373 - acc: 0.8486 - val_loss: 0.7775 - val_acc: 0.8010\n",
      "Learning rate:  0.001\n",
      "Epoch 28/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.6340 - acc: 0.8490Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 245us/sample - loss: 0.7939 - acc: 0.7930\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.82030\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.6341 - acc: 0.8490 - val_loss: 0.8316 - val_acc: 0.7930\n",
      "Learning rate:  0.001\n",
      "Epoch 29/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6337 - acc: 0.8493Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 252us/sample - loss: 0.6744 - acc: 0.8294\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.82030 to 0.82940, saving model to C:\\Users\\19244\\saved_models\\CNN_20_l2_model.h5\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.6337 - acc: 0.8493 - val_loss: 0.7171 - val_acc: 0.8294\n",
      "Learning rate:  0.001\n",
      "Epoch 30/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.6272 - acc: 0.8530- ETA: Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 242us/sample - loss: 0.8698 - acc: 0.8270\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.82940\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.6271 - acc: 0.8530 - val_loss: 0.7171 - val_acc: 0.8270\n",
      "Learning rate:  0.001\n",
      "Epoch 31/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.6278 - acc: 0.8517Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 246us/sample - loss: 0.7994 - acc: 0.8252\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.82940\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.6278 - acc: 0.8517 - val_loss: 0.7080 - val_acc: 0.8252\n",
      "Learning rate:  0.001\n",
      "Epoch 32/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6203 - acc: 0.8536Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 237us/sample - loss: 0.7473 - acc: 0.8108\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.82940\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.6203 - acc: 0.8536 - val_loss: 0.7860 - val_acc: 0.8108\n",
      "Learning rate:  0.001\n",
      "Epoch 33/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6208 - acc: 0.8554Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 243us/sample - loss: 1.0634 - acc: 0.7794\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.82940\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.6207 - acc: 0.8554 - val_loss: 0.9268 - val_acc: 0.7794\n",
      "Learning rate:  0.001\n",
      "Epoch 34/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6162 - acc: 0.8568Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 254us/sample - loss: 0.8360 - acc: 0.7773\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.82940\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6163 - acc: 0.8568 - val_loss: 0.9050 - val_acc: 0.7773\n",
      "Learning rate:  0.001\n",
      "Epoch 35/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.6098 - acc: 0.8591Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 251us/sample - loss: 1.1282 - acc: 0.7430\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.82940\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.6098 - acc: 0.8591 - val_loss: 0.9999 - val_acc: 0.7430\n",
      "Learning rate:  0.001\n",
      "Epoch 36/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.6089 - acc: 0.8597Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 272us/sample - loss: 0.9386 - acc: 0.7894\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.82940\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.6090 - acc: 0.8596 - val_loss: 0.8657 - val_acc: 0.7894\n",
      "Learning rate:  0.001\n",
      "Epoch 37/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6049 - acc: 0.8604Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 252us/sample - loss: 0.9076 - acc: 0.8064\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.82940\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.6048 - acc: 0.8605 - val_loss: 0.8034 - val_acc: 0.8064\n",
      "Learning rate:  0.001\n",
      "Epoch 38/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.6043 - acc: 0.8620Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 254us/sample - loss: 1.1486 - acc: 0.7549\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.82940\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6041 - acc: 0.8620 - val_loss: 1.0061 - val_acc: 0.7549\n",
      "Learning rate:  0.001\n",
      "Epoch 39/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6036 - acc: 0.8623Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 244us/sample - loss: 0.7575 - acc: 0.8135\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.82940\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6035 - acc: 0.8623 - val_loss: 0.7670 - val_acc: 0.8135\n",
      "Learning rate:  0.001\n",
      "Epoch 40/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6003 - acc: 0.8641Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 247us/sample - loss: 0.7509 - acc: 0.8262\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.82940\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.6003 - acc: 0.8641 - val_loss: 0.7212 - val_acc: 0.8262\n",
      "Learning rate:  0.001\n",
      "Epoch 41/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5954 - acc: 0.8656Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 242us/sample - loss: 0.8799 - acc: 0.8273\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.82940\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5954 - acc: 0.8657 - val_loss: 0.7347 - val_acc: 0.8273\n",
      "Learning rate:  0.001\n",
      "Epoch 42/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5910 - acc: 0.8667Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 257us/sample - loss: 0.9771 - acc: 0.7449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00042: val_acc did not improve from 0.82940\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5909 - acc: 0.8667 - val_loss: 1.1099 - val_acc: 0.7449\n",
      "Learning rate:  0.001\n",
      "Epoch 43/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5927 - acc: 0.8680Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 270us/sample - loss: 0.9496 - acc: 0.7797\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.82940\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.5928 - acc: 0.8680 - val_loss: 0.9336 - val_acc: 0.7797\n",
      "Learning rate:  0.001\n",
      "Epoch 44/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5919 - acc: 0.8674Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 258us/sample - loss: 0.9695 - acc: 0.8023\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.82940\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5921 - acc: 0.8674 - val_loss: 0.7974 - val_acc: 0.8023\n",
      "Learning rate:  0.001\n",
      "Epoch 45/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5866 - acc: 0.8693Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 256us/sample - loss: 0.7978 - acc: 0.8236\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.82940\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5866 - acc: 0.8693 - val_loss: 0.7252 - val_acc: 0.8236\n",
      "Learning rate:  0.001\n",
      "Epoch 46/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5836 - acc: 0.8687- ETA: 0s - loss: 0.5840 - acc: 0 - ETA: 0s - loss: 0.5839 - acc: Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 290us/sample - loss: 1.0015 - acc: 0.7997\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.82940\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5835 - acc: 0.8687 - val_loss: 0.8238 - val_acc: 0.7997\n",
      "Learning rate:  0.001\n",
      "Epoch 47/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5906 - acc: 0.8665  ETA: 10s - los - ETA: 9s - los - ETA: 1s - loss: 0Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 286us/sample - loss: 0.8246 - acc: 0.8199\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.82940\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.5905 - acc: 0.8665 - val_loss: 0.7577 - val_acc: 0.8199\n",
      "Learning rate:  0.001\n",
      "Epoch 48/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5843 - acc: 0.8693Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 305us/sample - loss: 0.7912 - acc: 0.8365\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.82940 to 0.83650, saving model to C:\\Users\\19244\\saved_models\\CNN_20_l2_model.h5\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.5844 - acc: 0.8693 - val_loss: 0.6963 - val_acc: 0.8365\n",
      "Learning rate:  0.001\n",
      "Epoch 49/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5821 - acc: 0.8709Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 4s 376us/sample - loss: 0.9273 - acc: 0.8090\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.83650\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.5819 - acc: 0.8710 - val_loss: 0.7985 - val_acc: 0.8090\n",
      "Learning rate:  0.001\n",
      "Epoch 50/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5846 - acc: 0.8693Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 347us/sample - loss: 0.7607 - acc: 0.8179\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.83650\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.5846 - acc: 0.8693 - val_loss: 0.7718 - val_acc: 0.8179\n",
      "Learning rate:  0.001\n",
      "Epoch 51/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5836 - acc: 0.8704Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 4s 401us/sample - loss: 1.2505 - acc: 0.7325\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.83650\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.5834 - acc: 0.8704 - val_loss: 1.1248 - val_acc: 0.7325\n",
      "Learning rate:  0.001\n",
      "Epoch 52/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5781 - acc: 0.8711Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 6s 585us/sample - loss: 0.6473 - acc: 0.8350\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.83650\n",
      "1563/1563 [==============================] - 82s 53ms/step - loss: 0.5780 - acc: 0.8711 - val_loss: 0.7114 - val_acc: 0.8350\n",
      "Learning rate:  0.001\n",
      "Epoch 53/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5772 - acc: 0.8732Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 306us/sample - loss: 0.7364 - acc: 0.8230\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.83650\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.5772 - acc: 0.8732 - val_loss: 0.7770 - val_acc: 0.8230\n",
      "Learning rate:  0.001\n",
      "Epoch 54/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5770 - acc: 0.8724Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 348us/sample - loss: 1.0059 - acc: 0.7501\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.83650\n",
      "1563/1563 [==============================] - 49s 32ms/step - loss: 0.5775 - acc: 0.8723 - val_loss: 1.1000 - val_acc: 0.7501\n",
      "Learning rate:  0.001\n",
      "Epoch 55/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5749 - acc: 0.8746- Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 346us/sample - loss: 0.8509 - acc: 0.8361\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.83650\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.5750 - acc: 0.8746 - val_loss: 0.7070 - val_acc: 0.8361\n",
      "Learning rate:  0.001\n",
      "Epoch 56/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5755 - acc: 0.8735Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 325us/sample - loss: 0.9060 - acc: 0.8059\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.83650\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.5755 - acc: 0.8735 - val_loss: 0.8033 - val_acc: 0.8059\n",
      "Learning rate:  0.001\n",
      "Epoch 57/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5713 - acc: 0.8761Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 346us/sample - loss: 0.8924 - acc: 0.7952\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.83650\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.5713 - acc: 0.8761 - val_loss: 0.8466 - val_acc: 0.7952\n",
      "Learning rate:  0.001\n",
      "Epoch 58/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5667 - acc: 0.8765Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 4s 354us/sample - loss: 0.8230 - acc: 0.8023\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.83650\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.5667 - acc: 0.8766 - val_loss: 0.8569 - val_acc: 0.8023\n",
      "Learning rate:  0.001\n",
      "Epoch 59/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5679 - acc: 0.8764Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 310us/sample - loss: 0.8490 - acc: 0.8374\n",
      "\n",
      "Epoch 00059: val_acc improved from 0.83650 to 0.83740, saving model to C:\\Users\\19244\\saved_models\\CNN_20_l2_model.h5\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.5677 - acc: 0.8764 - val_loss: 0.7113 - val_acc: 0.8374\n",
      "Learning rate:  0.001\n",
      "Epoch 60/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5719 - acc: 0.8756Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 301us/sample - loss: 1.0257 - acc: 0.8003\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.83740\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5718 - acc: 0.8757 - val_loss: 0.8411 - val_acc: 0.8003\n",
      "Learning rate:  0.001\n",
      "Epoch 61/100\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.5708 - acc: 0.8763Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 274us/sample - loss: 0.8585 - acc: 0.8273\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.83740\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5708 - acc: 0.8763 - val_loss: 0.7448 - val_acc: 0.8273\n",
      "Learning rate:  0.001\n",
      "Epoch 62/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5674 - acc: 0.8768Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 280us/sample - loss: 0.7007 - acc: 0.8266\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.83740\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.5673 - acc: 0.8768 - val_loss: 0.7201 - val_acc: 0.8266\n",
      "Learning rate:  0.001\n",
      "Epoch 63/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5646 - acc: 0.8775Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 291us/sample - loss: 0.6509 - acc: 0.8286\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.83740\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5647 - acc: 0.8775 - val_loss: 0.7448 - val_acc: 0.8286\n",
      "Learning rate:  0.001\n",
      "Epoch 64/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5665 - acc: 0.8773Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 302us/sample - loss: 0.8664 - acc: 0.7930\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.83740\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 0.5665 - acc: 0.8773 - val_loss: 0.9036 - val_acc: 0.7930\n",
      "Learning rate:  0.001\n",
      "Epoch 65/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5585 - acc: 0.8805Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 293us/sample - loss: 0.7820 - acc: 0.8496\n",
      "\n",
      "Epoch 00065: val_acc improved from 0.83740 to 0.84960, saving model to C:\\Users\\19244\\saved_models\\CNN_20_l2_model.h5\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.5586 - acc: 0.8805 - val_loss: 0.6725 - val_acc: 0.8496\n",
      "Learning rate:  0.001\n",
      "Epoch 66/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5602 - acc: 0.8790Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 289us/sample - loss: 0.7792 - acc: 0.8258\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.84960\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.5605 - acc: 0.8789 - val_loss: 0.7389 - val_acc: 0.8258\n",
      "Learning rate:  0.001\n",
      "Epoch 67/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5628 - acc: 0.8790Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 289us/sample - loss: 0.7234 - acc: 0.8230\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.84960\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.5626 - acc: 0.8790 - val_loss: 0.7568 - val_acc: 0.8230\n",
      "Learning rate:  0.001\n",
      "Epoch 68/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5593 - acc: 0.8794Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 285us/sample - loss: 0.7903 - acc: 0.8294\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.84960\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5592 - acc: 0.8793 - val_loss: 0.7345 - val_acc: 0.8294\n",
      "Learning rate:  0.001\n",
      "Epoch 69/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5613 - acc: 0.8794Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 284us/sample - loss: 0.8128 - acc: 0.8452\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.84960\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5612 - acc: 0.8794 - val_loss: 0.6870 - val_acc: 0.8452\n",
      "Learning rate:  0.001\n",
      "Epoch 70/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5601 - acc: 0.8795Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 241us/sample - loss: 0.7422 - acc: 0.8053\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.84960\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 0.5603 - acc: 0.8794 - val_loss: 0.8629 - val_acc: 0.8053\n",
      "Learning rate:  0.001\n",
      "Epoch 71/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5583 - acc: 0.8804Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 285us/sample - loss: 0.8811 - acc: 0.8143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00071: val_acc did not improve from 0.84960\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5582 - acc: 0.8805 - val_loss: 0.8222 - val_acc: 0.8143\n",
      "Learning rate:  0.001\n",
      "Epoch 72/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5563 - acc: 0.8806Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 341us/sample - loss: 0.7603 - acc: 0.8067\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.84960\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 0.5563 - acc: 0.8806 - val_loss: 0.8534 - val_acc: 0.8067\n",
      "Learning rate:  0.001\n",
      "Epoch 73/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5538 - acc: 0.8829Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 4s 357us/sample - loss: 0.6461 - acc: 0.8292\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.84960\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.5538 - acc: 0.8829 - val_loss: 0.7317 - val_acc: 0.8292\n",
      "Learning rate:  0.001\n",
      "Epoch 74/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5552 - acc: 0.8802Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 296us/sample - loss: 1.0606 - acc: 0.8118\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.84960\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.5551 - acc: 0.8803 - val_loss: 0.8084 - val_acc: 0.8118\n",
      "Learning rate:  0.001\n",
      "Epoch 75/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5590 - acc: 0.8811Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 4s 355us/sample - loss: 0.9482 - acc: 0.8095\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.84960\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5590 - acc: 0.8811 - val_loss: 0.8118 - val_acc: 0.8095\n",
      "Learning rate:  0.001\n",
      "Epoch 76/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5541 - acc: 0.8821Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 322us/sample - loss: 0.8990 - acc: 0.7784\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.84960\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5541 - acc: 0.8821 - val_loss: 0.8944 - val_acc: 0.7784\n",
      "Learning rate:  0.001\n",
      "Epoch 77/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5527 - acc: 0.8825Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 261us/sample - loss: 0.6208 - acc: 0.7993\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.84960\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5527 - acc: 0.8825 - val_loss: 0.8617 - val_acc: 0.7993\n",
      "Learning rate:  0.001\n",
      "Epoch 78/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5518 - acc: 0.8820Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 285us/sample - loss: 0.8303 - acc: 0.8426\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.84960\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5517 - acc: 0.8820 - val_loss: 0.6902 - val_acc: 0.8426\n",
      "Learning rate:  0.001\n",
      "Epoch 79/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5510 - acc: 0.8833Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 298us/sample - loss: 0.9123 - acc: 0.8058\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.84960\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.5510 - acc: 0.8834 - val_loss: 0.8478 - val_acc: 0.8058\n",
      "Learning rate:  0.001\n",
      "Epoch 80/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5524 - acc: 0.8835Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 345us/sample - loss: 0.8002 - acc: 0.8272\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.84960\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 0.5523 - acc: 0.8835 - val_loss: 0.7443 - val_acc: 0.8272\n",
      "Learning rate:  0.001\n",
      "Epoch 81/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5489 - acc: 0.8832Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 245us/sample - loss: 0.7693 - acc: 0.8186\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.84960\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 0.5489 - acc: 0.8832 - val_loss: 0.7628 - val_acc: 0.8186\n",
      "Learning rate:  0.0001\n",
      "Epoch 82/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.4577 - acc: 0.9149Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 247us/sample - loss: 0.6032 - acc: 0.8946\n",
      "\n",
      "Epoch 00082: val_acc improved from 0.84960 to 0.89460, saving model to C:\\Users\\19244\\saved_models\\CNN_20_l2_model.h5\n",
      "1563/1563 [==============================] - 40s 25ms/step - loss: 0.4576 - acc: 0.9149 - val_loss: 0.5325 - val_acc: 0.8946\n",
      "Learning rate:  0.0001\n",
      "Epoch 83/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.4212 - acc: 0.9265Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 258us/sample - loss: 0.5786 - acc: 0.8975\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.89460 to 0.89750, saving model to C:\\Users\\19244\\saved_models\\CNN_20_l2_model.h5\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.4213 - acc: 0.9264 - val_loss: 0.5252 - val_acc: 0.8975\n",
      "Learning rate:  0.0001\n",
      "Epoch 84/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.4059 - acc: 0.9300Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 245us/sample - loss: 0.5606 - acc: 0.8957\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.89750\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 0.4059 - acc: 0.9301 - val_loss: 0.5204 - val_acc: 0.8957\n",
      "Learning rate:  0.0001\n",
      "Epoch 85/100\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.3935 - acc: 0.9344Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 231us/sample - loss: 0.5598 - acc: 0.8998\n",
      "\n",
      "Epoch 00085: val_acc improved from 0.89750 to 0.89980, saving model to C:\\Users\\19244\\saved_models\\CNN_20_l2_model.h5\n",
      "1563/1563 [==============================] - 40s 25ms/step - loss: 0.3935 - acc: 0.9344 - val_loss: 0.5119 - val_acc: 0.8998\n",
      "Learning rate:  0.0001\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.3861 - acc: 0.9357Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 227us/sample - loss: 0.5966 - acc: 0.9004\n",
      "\n",
      "Epoch 00086: val_acc improved from 0.89980 to 0.90040, saving model to C:\\Users\\19244\\saved_models\\CNN_20_l2_model.h5\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3859 - acc: 0.9358 - val_loss: 0.5151 - val_acc: 0.9004\n",
      "Learning rate:  0.0001\n",
      "Epoch 87/100\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.3750 - acc: 0.9382Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 247us/sample - loss: 0.5978 - acc: 0.9002\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.90040\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3750 - acc: 0.9382 - val_loss: 0.5071 - val_acc: 0.9002\n",
      "Learning rate:  0.0001\n",
      "Epoch 88/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.3728 - acc: 0.9378Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 246us/sample - loss: 0.5314 - acc: 0.9027\n",
      "\n",
      "Epoch 00088: val_acc improved from 0.90040 to 0.90270, saving model to C:\\Users\\19244\\saved_models\\CNN_20_l2_model.h5\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3728 - acc: 0.9378 - val_loss: 0.4986 - val_acc: 0.9027\n",
      "Learning rate:  0.0001\n",
      "Epoch 89/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.3625 - acc: 0.9419Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 228us/sample - loss: 0.5608 - acc: 0.9037\n",
      "\n",
      "Epoch 00089: val_acc improved from 0.90270 to 0.90370, saving model to C:\\Users\\19244\\saved_models\\CNN_20_l2_model.h5\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3625 - acc: 0.9419 - val_loss: 0.4929 - val_acc: 0.9037\n",
      "Learning rate:  0.0001\n",
      "Epoch 90/100\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.3587 - acc: 0.9410- ETA: 8s - loss: 0.3578 - acc: 0. - ETA: 8s - loss: 0.3575 - ETA: 7s - los - ETA: 3s - loss: 0.3581 - acc: 0 - ETA: 3s -  - ETA: 1s - loss: 0.3 - ETA: 0s - loss: 0.3585 - acc: 0.9Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 224us/sample - loss: 0.5765 - acc: 0.9033\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.90370\n",
      "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3587 - acc: 0.9410 - val_loss: 0.4957 - val_acc: 0.9033\n",
      "Learning rate:  0.0001\n",
      "Epoch 91/100\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.3524 - acc: 0.9422Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 248us/sample - loss: 0.5371 - acc: 0.8996\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.90370\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3523 - acc: 0.9423 - val_loss: 0.5078 - val_acc: 0.8996\n",
      "Learning rate:  0.0001\n",
      "Epoch 92/100\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.3482 - acc: 0.9441Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 270us/sample - loss: 0.5353 - acc: 0.9054\n",
      "\n",
      "Epoch 00092: val_acc improved from 0.90370 to 0.90540, saving model to C:\\Users\\19244\\saved_models\\CNN_20_l2_model.h5\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.3482 - acc: 0.9441 - val_loss: 0.4900 - val_acc: 0.9054\n",
      "Learning rate:  0.0001\n",
      "Epoch 93/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.3429 - acc: 0.9443Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 259us/sample - loss: 0.5562 - acc: 0.9026\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.90540\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3429 - acc: 0.9443 - val_loss: 0.4888 - val_acc: 0.9026\n",
      "Learning rate:  0.0001\n",
      "Epoch 94/100\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.3390 - acc: 0.9452Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 248us/sample - loss: 0.5397 - acc: 0.9024\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.90540\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3392 - acc: 0.9452 - val_loss: 0.4980 - val_acc: 0.9024\n",
      "Learning rate:  0.0001\n",
      "Epoch 95/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.3349 - acc: 0.9462Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 253us/sample - loss: 0.5513 - acc: 0.9016\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.90540\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3348 - acc: 0.9463 - val_loss: 0.4995 - val_acc: 0.9016\n",
      "Learning rate:  0.0001\n",
      "Epoch 96/100\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.3296 - acc: 0.9458Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 247us/sample - loss: 0.5926 - acc: 0.9029\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.90540\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3296 - acc: 0.9457 - val_loss: 0.4915 - val_acc: 0.9029\n",
      "Learning rate:  0.0001\n",
      "Epoch 97/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.3259 - acc: 0.9474Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 245us/sample - loss: 0.5648 - acc: 0.9023\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.90540\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3259 - acc: 0.9474 - val_loss: 0.4958 - val_acc: 0.9023\n",
      "Learning rate:  0.0001\n",
      "Epoch 98/100\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.3223 - acc: 0.9486Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 249us/sample - loss: 0.5387 - acc: 0.9032\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.90540\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3222 - acc: 0.9486 - val_loss: 0.4850 - val_acc: 0.9032\n",
      "Learning rate:  0.0001\n",
      "Epoch 99/100\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.3141 - acc: 0.9510Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 3s 274us/sample - loss: 0.5748 - acc: 0.9018\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.90540\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.3140 - acc: 0.9511 - val_loss: 0.5020 - val_acc: 0.9018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.0001\n",
      "Epoch 100/100\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.3120 - acc: 0.9513Epoch 1/100\n",
      "10000/1563 [===============================================================================================================================================================================================] - 2s 247us/sample - loss: 0.5273 - acc: 0.9022\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.90540\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3120 - acc: 0.9512 - val_loss: 0.4972 - val_acc: 0.9022\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit_generator(datagen.flow(X_train, Y_train, batch_size=32),\n",
    "                              epochs = 100, \n",
    "                              validation_data=(X_test, Y_test),\n",
    "                              callbacks=[scheduler, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc1 = history1.history['acc']\n",
    "val_acc1 = history1.history['val_acc']\n",
    "\n",
    "fig1,ax1 = plt.subplots(1,1,figsize=(10,6))\n",
    "\n",
    "ax1.plot(acc1, label='Training Accuracy')\n",
    "ax1.plot(val_acc1, label='Validation Accuracy')\n",
    "\n",
    "ax1.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax1.set_ylabel(r'Acc', fontsize=20)\n",
    "ax1.set_title('plain CNN20', fontsize=24)\n",
    "\n",
    "ax1.tick_params(labelsize=20)\n",
    "\n",
    "ax1.legend(loc=4, fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
